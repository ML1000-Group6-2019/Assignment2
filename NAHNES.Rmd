---
title: 'ML Assignment 2: NHANES data'
author:
  - name: Imran Aziz
  - name: Conrard G. T. Feugmo
  - name: Andre Schardong
  - name: Milton Segura
  - name: Sarpreet Gill
    affiliation: York University School of Continuing Studies
date: "Oct 6, 2019"
output:
  pdf_document:
    includes:
      in_header: preamble.tex
  html_document:
    toc: true
    toc_float:
      collapsed: true
      smooth_scroll: true
---
```{r setup, include=FALSE, warning = F}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.pos = 'H')
knitr::opts_chunk$set(comment=FALSE)
knitr::opts_chunk$set(warning=FALSE)
```

\newpage

# Introduction: 

The following is a hypothetical business problem: A pharmaceutical company is looking to better understand what the data related to subjects and various health conditions and miscellaneous attributes.

* **Terms** 

  **Subject** - is a person who has been surveyed by the NHMS dataset for various attributes related to the following: demographics, examinations, dietary, questionnaire(medical conditions), and medication
  
  **Health Conditions** - various diseases or ailments that people may inhibit such as sleep disorders, diabetes, oral health, cholesterol.  
  
  **The National Health and Nutrition Examination Survey (NHANES)** - is a program of studies designed to assess the health and nutritional status of adults and children in the 


* **Data Description**

The data is spread against 6 spreadsheets (CSV): Demographics, Examinations, Dietary, Laboratory, Questionnaire, and Medication.

# Business Case

A pharmaceutical company wants to produce new drugs.  The company is curious as to whether existing data on subjects and their associated health conditions could provide advice and insight to their drug researchers.  They have obtained NHMS dataset.  This dataset contains subject/patient data along with various information including health conditions.  

The company is interested in producing new drugs for the following health conditions: diabetes and hypertension/cholesterol (we can add or remove health conditions later.  At the very least, let’s keep diabetes or something). 


## First Problem: 
What types of symptoms, medications, diet, demographics are common among various health conditions (such as diabetes)?  For example, what types of dietary factors are  commonly found with diabetes?        

## Second Problem: 
Are their any commonalities between various people with the same health conditions?  For example, if subject 1 and subject 2 have the same health condition (for example, diabetes) what other similarities would these subjects have?  

They have approached our Machine Learning group for help on these problems.  

# Analytical Reframing for the Business Case.  

The first business problem involves using “health condition” features and finding related features.  This is an association problem and we will need a model using an association algorithm.  


* What features are associated with “health condition” features? 

* We’re comparing the rows of the dataset.  

The second business problem involves finding commonality between subjects.  This is a clustering problem and we will need a model using a clustering algorithm.   We need to determine whether business’s presumption is accurate:  

* Can subjects be divided into discrete groups according to their health conditions, which could then provide meaningful data for the drug researchers?  If yes, we need to find these clusters of subjects that can be used to segregate the data by health conditions, then we can report these findings to the business.  

* Or is there too much commonality between “health condition” features and other features?

* If we cannot find clusters that could be divided by health conditions, then we will also report this finding to the company as well and note that clusters that we did find.  We’re comparing the columns/attributes of the dataset.   

## How do we define health conditions within the dataset ? 

How do we know what is considered a health condition within the data? We could use lab data and diagnose whether someone falls under the definition of health condition; however, for the purpose 

Diabetes within Questionnaire dataset: 

We are postulating that the following features/columns indicate that an individual has diabetes

DID040 - "How old {was SP/were you} when a doctor or other health professional first told {you/him/her} that {you/he/she} had diabetes or sugar diabetes?"

DID060 - "For how long {have you/has SP} been taking insulin?"

NA in the above features might indicate the subject does not have diabetes.  

For the association problem, we will need to see which attributes are tied to above features.

Blood Pressure within Questionnaire dataset

BPD035 - How old {were you/was SP} when {you were/he/she was} first told that {you/he/she} had hypertension or high blood pressure?

BPQ020 - {Have you/Has SP} ever been told by a doctor or other health professional that {you/s/he} had hypertension, also called high blood pressure?

Cancer 

MCQ220 - {Have you/Has SP} ever been told by a doctor or other health professional that {you/s/he} had cancer or a malignancy (ma-lig-nan-see) of any kind?  





 

# Loading R packages

```{r,warning = F, message=F}
library(plyr)
library(dplyr)
library(tidyr)
library(ggplot2)
library(knitr)
```


# Data cleaning

<Describe what needs to happen to the data files> 

As indicated eariler, the dataset conists of 6 raw data files: Demographics, Examinations, Dietary, Laboratory, Questionnaire, and Medication.  The largest file (in terms of attributes) is the questionnaire data contains 953 variables; while the smallest data file contains 47 variables.  This is a large amount of data.  Cumatavitely, there are 1000s of attributes, therefore, we have decided need to employ the following guidelines to assist with reducing the complexity of the data: 

- If more than 25% of the values are missing for an attribute(column), we will consider removing the column from further evaluation.
- If the majority of attributes are missing 25% or more of their values for a given dataset, we will use personal or business judgmement to subjectively select a smaller subset of "interesting" values.  Of these subset of missing values, we will then decide how to impute the values on these attributes.     

Ideally, we would like to analyse and impute every attribute with missing values, but in this situation, it may not be practical due to the large volume of missing data. 


```{r, warning = F, message=F}
# Reading files
demographic   = read.csv("Data/Raw/demographic.csv", header = TRUE, na.strings = c("NA","","#NA"))
diet          = read.csv("Data/Raw/diet.csv", header = TRUE, na.strings = c("NA","","#NA"))
examination   = read.csv("Data/Raw/examination.csv", header = TRUE, na.strings = c("NA","","#NA"))
labs          = read.csv("Data/Raw/labs.csv", header = TRUE, na.strings = c("NA","","#NA"))
medications   = read.csv("Data/Raw/medications.csv", header = TRUE, na.strings = c("NA","","#NA"))
questionnaire = read.csv("Data/Raw/questionnaire.csv", header = TRUE, na.strings = c("NA","","#NA"))

# Merging files
data_List = list(demographic,examination,diet,labs,questionnaire,medications)
Data_joined = join_all(data_List) #require(plyr)

```


```{r, eval=FALSE, echo=TRUE}

```



## Checking for missing data

Its always important to check for missing values and consider how to fix them.

* **Demographic**

````{r, warning = F, message=F}
library(plotly)
```
````{r, eval=TRUE, echo=TRUE, warning = F, message=F}
demographic_MS <- demographic %>% summarise_all(~(sum(is.na(.))/n()))
demographic_MS <- gather(demographic_MS, key = "variables", value = "percent_missing")
demographic_MS <- demographic_MS[demographic_MS$percent_missing > 0.0, ] 

demographic_MS_plot  <- ggplot(demographic_MS, aes(x = reorder(variables, percent_missing), y = percent_missing)) +
  geom_bar(stat = "identity", fill = "blue", aes(color = I('white')), size = 0.3, alpha = 0.8)+
  xlab('variables')+
  coord_flip()+ 
  #theme_fivethirtyeight() +
  ggtitle("Demographic Missing Data By Columns")

demographic_MS_plot
```




<!--```{r,include=TRUE, fig.align="center", echo=T} -->
<!--#library(knitr)-->
<!--#knitr::include_graphics("Figures/demographic_MS.png")-->
<!--```-->

*  **Medications**


```{r, eval=TRUE, echo=TRUE, warning = F, message=F}
medications_MS <- medications %>% summarise_all(~(sum(is.na(.))/n()))
medications_MS <- gather(medications_MS, key = "variables", value = "percent_missing")
medications_MS <- medications_MS[medications_MS$percent_missing > 0.0, ] 

medications_MS_plot <- ggplot(medications_MS, aes(x = reorder(variables, percent_missing), y = percent_missing)) +
  geom_bar(stat = "identity", fill = "blue", aes(color = I('white')), size = 0.3, alpha = 0.8)+
  xlab('variables')+
  coord_flip()+ 
  #theme_fivethirtyeight() +
  ggtitle("Medications Missing Data By Columns")

medications_MS_plot
```

<!--```{r,include=TRUE, fig.align="center", echo=T}-->
<!--#library(knitr)-->
<!--#knitr::include_graphics("Figures/medications_MS.png")-->
<!--```-->

*  **Others spreadsheets **

We didn't represent the other spreadsheets because the percentage of missing data is very significant. For example, the following:

*  **Examination**
```{r, eval=TRUE, echo=TRUE, warning = F, message=F}
examination_MS <- examination %>% summarise_all(~(sum(is.na(.))/n()))
examination_MS <- gather(examination_MS, key = "variables", value = "percent_missing")
examination_MS <- examination_MS[examination_MS$percent_missing > 0.0, ] 

examination_MS_plot <- ggplot(examination_MS, aes(x = reorder(variables, percent_missing), y = percent_missing)) +
  geom_bar(stat = "identity", fill = "blue", aes(color = I('white')), size = 0.3, alpha = 0.8)+
  xlab('variables')+
  coord_flip()+ 
  #theme_fivethirtyeight() +
  ggtitle("Examination Missing Data By Columns")

examination_MS_plot

```  
  
  
<!--```{r,include=TRUE, fig.align="center", echo=T}  -->
<!--#library(knitr) -->
<!--knitr::include_graphics("Figures/examination_MS.png")-->
<!--```-->


*  **Diet**
```{r, eval=TRUE, echo=TRUE, warning = F, message=F}
diet_MS <- diet %>% summarise_all(~(sum(is.na(.))/n()))
diet_MS <- gather(diet_MS, key = "variables", value = "percent_missing")
diet_MS <- diet_MS[diet_MS$percent_missing > 0.0, ] 
diet_MS_plot <- ggplot(diet_MS, aes(x = reorder(variables, percent_missing), y = percent_missing)) +
  geom_bar(stat = "identity", fill = "blue", aes(color = I('white')), size = 0.3, alpha = 0.8)+
  xlab('variables')+
  coord_flip()+ 
  #theme_fivethirtyeight() +
  ggtitle("Diet Missing Data By Columns")

```
 
 Almost all columns/attributes have varying degrees of missing values.  As per our guidelines, we will choose and select "interesting" attributes/columns based on our business/personal judgements.  The NHANES data dictionary/variable list is listed as follows:   

https://wwwn.cdc.gov/Nchs/Nhanes/Search/variablelist.aspx?Component=Dietary&CycleBeginYear=2013

The data is divded into the following sections:  <list sections>

We have inspected the above data dictionary and we have selected the following interesting values for further analysis.   

diet_subset -> Need to impute it.  

These variables/attributes are referring to the one day nutrituion numerical attributes.  


## Data splitting & imputation

There are many ways to do data imputation, but random forest imputation will be used since it is robust and reliable method.

```{r, eval=FALSE, echo=TRUE}

```

## Visualising all numeric columns

It is useful to show histograms of all numeric columns.

```{r, eval=FALSE, echo=TRUE}

```

## Visualising correlation

```{r, eval=FALSE, echo=TRUE}

```

## Exploring by location

```{r, eval=FALSE, echo=TRUE}

```

## Exploring by age 

```{r, eval=FALSE, echo=TRUE}

```

# Problem 1: Clustering

```{r, eval=FALSE, echo=TRUE}

```

##  PCA

```{r, eval=FALSE, echo=TRUE}

```

##  K-means 

```{r, eval=FALSE, echo=TRUE}

```

##  Hierarchical Agglomerative

```{r, eval=FALSE, echo=TRUE}

```

##  Summary of models

```{r, eval=FALSE, echo=TRUE}

```


# Problem 2: Association

```{r, eval=FALSE, echo=TRUE}

```









